---
import Layout from '../../../layouts/Layout.astro'
---

<Layout title="AI Models & Providers - George-AI Documentation">
  <div class="max-w-4xl mx-auto">
    <!-- Breadcrumb -->
    <div class="text-sm breadcrumbs mb-6">
      <ul>
        <li><a href="/docs">Documentation</a></li>
        <li><a href="/docs">Administration</a></li>
        <li>AI Models & Providers</li>
      </ul>
    </div>

    <!-- Header -->
    <div class="mb-8">
      <div class="badge badge-primary mb-4">Administration</div>
      <h1 class="text-5xl font-bold mb-4">AI Models & Providers</h1>
      <p class="text-xl text-base-content/70">
        Manage AI models from multiple providers and configure them for embeddings, chat, and document processing
      </p>
    </div>

    <!-- Overview -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-4">Overview</h2>
      <div class="prose max-w-none">
        <p class="text-lg">
          George AI supports multiple AI providers simultaneously, giving you flexibility to choose the best models for your use case.
        </p>
        <p>
          All providers are <strong>optional</strong> - you can run George AI with Ollama only, OpenAI only, both, or neither (app runs but AI features are disabled until configured).
        </p>
      </div>

      <div class="grid md:grid-cols-2 gap-4 mt-6">
        <div class="stat bg-base-200 rounded-lg">
          <div class="stat-figure text-primary">
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-8 h-8 stroke-current">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
            </svg>
          </div>
          <div class="stat-title">Supported Providers</div>
          <div class="stat-value text-primary text-3xl">6+</div>
          <div class="stat-desc">2 stable, 4 planned (Anthropic, Google, Azure, HF)</div>
        </div>

        <div class="stat bg-base-200 rounded-lg">
          <div class="stat-figure text-secondary">
            <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-8 h-8 stroke-current">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path>
            </svg>
          </div>
          <div class="stat-title">Auto-Detection</div>
          <div class="stat-value text-secondary text-3xl">100%</div>
          <div class="stat-desc">Model capabilities detected automatically</div>
        </div>
      </div>
    </section>

    <!-- Supported Providers -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Supported Providers</h2>
      <div class="overflow-x-auto">
        <table class="table table-zebra">
          <thead>
            <tr>
              <th>Provider</th>
              <th>Status</th>
              <th>Capabilities</th>
              <th>Best For</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>
                <div class="font-bold">Ollama</div>
                <div class="text-sm opacity-70">Local models</div>
              </td>
              <td><span class="badge badge-success">Stable</span></td>
              <td class="text-sm">Chat, Embedding, Vision</td>
              <td class="text-sm">Privacy, offline use, self-hosted</td>
            </tr>
            <tr>
              <td>
                <div class="font-bold">OpenAI</div>
                <div class="text-sm opacity-70">API-Key models</div>
              </td>
              <td><span class="badge badge-success">Stable</span></td>
              <td class="text-sm">Chat, Embedding, Vision, Function Calling</td>
              <td class="text-sm">Performance, reliability, latest models</td>
            </tr>
            <tr>
              <td>
                <div class="font-bold">Anthropic (Claude)</div>
                <div class="text-sm opacity-70">Claude 3.5 Sonnet/Haiku</div>
              </td>
              <td><span class="badge badge-warning">Planned</span></td>
              <td class="text-sm">Chat, Vision, Function Calling</td>
              <td class="text-sm">Long context (200K), reasoning</td>
            </tr>
            <tr>
              <td>
                <div class="font-bold">Google AI (Gemini)</div>
                <div class="text-sm opacity-70">Gemini 2.0 Flash, 1.5 Pro</div>
              </td>
              <td><span class="badge badge-warning">Planned</span></td>
              <td class="text-sm">Chat, Embedding, Vision, Audio, Video</td>
              <td class="text-sm">Multimodal, long context (2M), cost-effective</td>
            </tr>
            <tr>
              <td>
                <div class="font-bold">Hugging Face</div>
                <div class="text-sm opacity-70">Open model hub</div>
              </td>
              <td><span class="badge badge-warning">Planned</span></td>
              <td class="text-sm">Chat, Embedding, Vision, Specialized</td>
              <td class="text-sm">Open models, experimentation, custom fine-tuning</td>
            </tr>
            <tr>
              <td>
                <div class="font-bold">Azure OpenAI</div>
                <div class="text-sm opacity-70">Enterprise cloud</div>
              </td>
              <td><span class="badge badge-warning">Planned</span></td>
              <td class="text-sm">Chat, Embedding, Vision, Function Calling</td>
              <td class="text-sm">Enterprise compliance, regional data residency</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- Provider Roadmap -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Provider Support Roadmap</h2>
      <div class="prose max-w-none mb-6">
        <p>
          George AI is expanding support for multiple AI providers to give you flexibility, cost optimization, and access to the best models for your use case.
        </p>
      </div>

      <!-- Tier 1: High Priority -->
      <div class="mb-8">
        <div class="flex items-center gap-3 mb-4">
          <h3 class="text-2xl font-bold">Tier 1: High Priority</h3>
          <span class="badge badge-error">P1-high</span>
        </div>
        <div class="grid md:grid-cols-2 gap-4">
          <!-- Anthropic -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Anthropic (Claude)
                <a href="https://github.com/progwise/george-ai/issues/866" target="_blank" class="link link-primary text-sm font-normal">#866</a>
              </h4>
              <p class="text-sm opacity-70">Claude 3.5 Sonnet, Claude 3.5 Haiku</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Vision</span>
                <span class="badge badge-sm">Function Calling</span>
              </div>
              <p class="text-sm mt-2">Long context (200K tokens), excellent reasoning, enterprise adoption</p>
            </div>
          </div>

          <!-- Google AI -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Google AI (Gemini)
                <a href="https://github.com/progwise/george-ai/issues/867" target="_blank" class="link link-primary text-sm font-normal">#867</a>
              </h4>
              <p class="text-sm opacity-70">Gemini 2.0 Flash, Gemini 1.5 Pro</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Embedding</span>
                <span class="badge badge-sm">Vision</span>
                <span class="badge badge-sm badge-accent">Audio</span>
                <span class="badge badge-sm badge-accent">Video</span>
              </div>
              <p class="text-sm mt-2">Multimodal leader, ultra-long context (2M tokens), cost-effective</p>
            </div>
          </div>

          <!-- Hugging Face -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Hugging Face
                <a href="https://github.com/progwise/george-ai/issues/868" target="_blank" class="link link-primary text-sm font-normal">#868</a>
              </h4>
              <p class="text-sm opacity-70">500,000+ open models</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Embedding</span>
                <span class="badge badge-sm">Vision</span>
                <span class="badge badge-sm badge-accent">Specialized</span>
              </div>
              <p class="text-sm mt-2">Open models, custom fine-tuning, domain-specific models (legal, medical, code)</p>
            </div>
          </div>

          <!-- Azure OpenAI -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Azure OpenAI
                <a href="https://github.com/progwise/george-ai/issues/869" target="_blank" class="link link-primary text-sm font-normal">#869</a>
              </h4>
              <p class="text-sm opacity-70">GPT-4o, GPT-4 Turbo, GPT-3.5</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Embedding</span>
                <span class="badge badge-sm">Vision</span>
                <span class="badge badge-sm">Function Calling</span>
              </div>
              <p class="text-sm mt-2">Enterprise compliance (HIPAA, SOC2), regional data residency, Microsoft ecosystem</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Tier 2: Medium Priority -->
      <div class="mb-8">
        <div class="flex items-center gap-3 mb-4">
          <h3 class="text-2xl font-bold">Tier 2: Medium Priority</h3>
          <span class="badge badge-warning">P2-medium</span>
        </div>
        <div class="grid md:grid-cols-2 gap-4">
          <!-- Mistral AI -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Mistral AI
                <a href="https://github.com/progwise/george-ai/issues/870" target="_blank" class="link link-primary text-sm font-normal">#870</a>
              </h4>
              <p class="text-sm opacity-70">Mistral Large 2, Mistral Small</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Embedding</span>
                <span class="badge badge-sm">Function Calling</span>
              </div>
              <p class="text-sm mt-2">European provider, GDPR-compliant, high-performance open models</p>
            </div>
          </div>

          <!-- Cohere -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Cohere
                <a href="https://github.com/progwise/george-ai/issues/871" target="_blank" class="link link-primary text-sm font-normal">#871</a>
              </h4>
              <p class="text-sm opacity-70">Command R+, Embed v3</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm">Chat</span>
                <span class="badge badge-sm">Embedding</span>
                <span class="badge badge-sm badge-accent">Reranking</span>
              </div>
              <p class="text-sm mt-2">RAG specialists, multilingual (100+ languages), unique reranking capabilities</p>
            </div>
          </div>
        </div>
      </div>

      <!-- Tier 3: Lower Priority -->
      <div class="mb-8">
        <div class="flex items-center gap-3 mb-4">
          <h3 class="text-2xl font-bold">Tier 3: Lower Priority</h3>
          <span class="badge badge-info">P3-low</span>
        </div>
        <div class="grid md:grid-cols-3 gap-4">
          <!-- AWS Bedrock -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                AWS Bedrock
                <a href="https://github.com/progwise/george-ai/issues/872" target="_blank" class="link link-primary text-sm font-normal">#872</a>
              </h4>
              <p class="text-sm opacity-70">Multi-provider platform</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm badge-xs">Chat</span>
                <span class="badge badge-sm badge-xs">Embedding</span>
              </div>
              <p class="text-sm mt-2">AWS-native, unified access to Anthropic, Meta, Cohere</p>
            </div>
          </div>

          <!-- Groq -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Groq
                <a href="https://github.com/progwise/george-ai/issues/873" target="_blank" class="link link-primary text-sm font-normal">#873</a>
              </h4>
              <p class="text-sm opacity-70">Ultra-fast inference</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm badge-xs">Chat</span>
                <span class="badge badge-sm badge-accent badge-xs">Speed</span>
              </div>
              <p class="text-sm mt-2">500+ tokens/sec, real-time applications, low latency</p>
            </div>
          </div>

          <!-- Together.ai -->
          <div class="card bg-base-100 shadow-lg">
            <div class="card-body">
              <h4 class="card-title text-lg">
                Together.ai
                <a href="https://github.com/progwise/george-ai/issues/874" target="_blank" class="link link-primary text-sm font-normal">#874</a>
              </h4>
              <p class="text-sm opacity-70">100+ open models</p>
              <div class="flex flex-wrap gap-2 mt-2">
                <span class="badge badge-sm badge-xs">Chat</span>
                <span class="badge badge-sm badge-xs">Embedding</span>
                <span class="badge badge-sm badge-accent badge-xs">Fine-tuning</span>
              </div>
              <p class="text-sm mt-2">Custom model deployment, bleeding edge releases</p>
            </div>
          </div>
        </div>
      </div>

      <div class="alert alert-info">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </svg>
        <div>
          <h3 class="font-bold">Want to Contribute?</h3>
          <p class="text-sm">Provider implementation is a great way to contribute to George AI! Check the linked GitHub issues for implementation details, or suggest a new provider we should add.</p>
        </div>
      </div>
    </section>

    <!-- Managing AI Models -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Managing AI Models</h2>
      <div class="card bg-base-200">
        <div class="card-body">
          <div class="space-y-4">
            <div class="flex items-start gap-4">
              <div class="badge badge-primary badge-lg">1</div>
              <div>
                <h4 class="font-bold mb-1">Navigate to AI Models</h4>
                <p class="text-sm text-base-content/70">Go to Admin Panel ‚Üí AI Models</p>
                <p class="text-sm text-base-content/70 mt-1">URL: <code class="text-xs">/admin/ai-models</code></p>
              </div>
            </div>
            <div class="flex items-start gap-4">
              <div class="badge badge-primary badge-lg">2</div>
              <div>
                <h4 class="font-bold mb-1">Sync Models from Providers</h4>
                <p class="text-sm text-base-content/70">Click the "Sync Models" button to discover available models</p>
                <p class="text-sm text-base-content/70 mt-1">This will:</p>
                <ul class="list-disc list-inside text-sm text-base-content/70 ml-4 mt-1 space-y-1">
                  <li>Connect to all configured providers (Ollama, OpenAI)</li>
                  <li>Discover available models</li>
                  <li>Auto-detect capabilities (embedding, chat, vision, function calling)</li>
                  <li>Update existing models (if already synced)</li>
                </ul>
              </div>
            </div>
            <div class="flex items-start gap-4">
              <div class="badge badge-primary badge-lg">3</div>
              <div>
                <h4 class="font-bold mb-1">Enable/Disable Models</h4>
                <p class="text-sm text-base-content/70">Toggle models on/off to control which ones appear in selection dropdowns</p>
                <div class="alert alert-info mt-2">
                  <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
                  <span class="text-sm">Disabled models are hidden from users but remain in the database for historical usage tracking</span>
                </div>
              </div>
            </div>
            <div class="flex items-start gap-4">
              <div class="badge badge-primary badge-lg">4</div>
              <div>
                <h4 class="font-bold mb-1">View Statistics</h4>
                <p class="text-sm text-base-content/70">See usage statistics for each model:</p>
                <ul class="list-disc list-inside text-sm text-base-content/70 ml-4 mt-1 space-y-1">
                  <li>Total requests</li>
                  <li>Total tokens processed</li>
                  <li>Used by (Libraries, Assistants, List Fields)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Workspace Filtering -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Workspace-Scoped Model Availability</h2>
      <div class="prose max-w-none mb-4">
        <p class="text-lg">
          Model dropdowns automatically filter based on your current workspace's configured AI providers.
        </p>
        <p>
          This means users only see models from providers that are enabled in their current workspace, ensuring proper access control and preventing confusion.
        </p>
      </div>

      <div class="alert alert-info mb-6">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
        </svg>
        <div>
          <h3 class="font-bold">How It Works</h3>
          <p class="text-sm">When you select a model for libraries, assistants, or list fields, George AI automatically shows only models from providers configured in your current workspace. Switching workspaces updates available models in real-time.</p>
        </div>
      </div>

      <div class="grid md:grid-cols-2 gap-6">
        <div class="card bg-base-200">
          <div class="card-body">
            <h3 class="card-title text-lg">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="w-6 h-6 stroke-current mr-2 text-success">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path>
              </svg>
              Benefits
            </h3>
            <ul class="list-disc list-inside text-sm space-y-1">
              <li>Zero configuration - filtering happens automatically</li>
              <li>Users can't accidentally select unavailable models</li>
              <li>Each workspace can use different AI providers</li>
              <li>Real-time updates when switching workspaces</li>
              <li>Applies to all model selections (embedding, chat, OCR)</li>
            </ul>
          </div>
        </div>

        <div class="card bg-base-200">
          <div class="card-body">
            <h3 class="card-title text-lg">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="w-6 h-6 stroke-current mr-2 text-info">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path>
              </svg>
              Example
            </h3>
            <div class="text-sm space-y-2">
              <p><strong>Workspace A:</strong> Configured with OpenAI</p>
              <p class="text-xs opacity-70">Users see: gpt-4o, gpt-4o-mini, text-embedding-3-small, etc.</p>
              <p class="mt-3"><strong>Workspace B:</strong> Configured with Ollama</p>
              <p class="text-xs opacity-70">Users see: qwen3, gemma3, nomic-embed-text, etc.</p>
            </div>
          </div>
        </div>
      </div>

      <div class="card bg-base-200 mt-6">
        <div class="card-body">
          <h3 class="card-title text-lg mb-4">Checking Available Models</h3>
          <div class="space-y-3">
            <div class="flex items-start gap-3">
              <div class="badge badge-primary">1</div>
              <div>
                <p class="font-semibold">Switch to your target workspace</p>
                <p class="text-sm opacity-70">Use the workspace switcher in the top navigation</p>
              </div>
            </div>
            <div class="flex items-start gap-3">
              <div class="badge badge-primary">2</div>
              <div>
                <p class="font-semibold">Open any model selection dropdown</p>
                <p class="text-sm opacity-70">Library embedding models, assistant language models, etc.</p>
              </div>
            </div>
            <div class="flex items-start gap-3">
              <div class="badge badge-primary">3</div>
              <div>
                <p class="font-semibold">View workspace-filtered models</p>
                <p class="text-sm opacity-70">Only models from workspace providers are shown</p>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="alert alert-warning mt-6">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path>
        </svg>
        <span><strong>Note:</strong> If no providers are configured in a workspace, model dropdowns will be empty. Admins should configure at least one provider via <a href="/docs/admin/ai-services" class="link">AI Services</a>.</span>
      </div>

      <div class="prose max-w-none mt-6">
        <p>For detailed information about workspaces and provider configuration, see the <a href="/docs/workspaces" class="link link-primary">Workspace Documentation</a>.</p>
      </div>
    </section>

    <!-- Model Capabilities -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Understanding Model Capabilities</h2>
      <div class="prose max-w-none mb-4">
        <p>Each model is automatically tagged with capabilities based on its name and provider information:</p>
      </div>
      <div class="grid md:grid-cols-2 gap-4">
        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-6 h-6 stroke-current text-primary">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 8h10M7 12h4m1 8l-4-4H5a2 2 0 01-2-2V6a2 2 0 012-2h14a2 2 0 012 2v8a2 2 0 01-2 2h-3l-4 4z"></path>
              </svg>
              Chat Completion
            </h3>
            <p class="text-sm">For Assistants - conversational AI, question answering</p>
            <p class="text-xs text-base-content/70 mt-2">Examples: gpt-4o, qwen3, gemma3</p>
          </div>
        </div>

        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-6 h-6 stroke-current text-secondary">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path>
              </svg>
              Embeddings
            </h3>
            <p class="text-sm">For Libraries - semantic search, vector generation</p>
            <p class="text-xs text-base-content/70 mt-2">Examples: text-embedding-3-small, nomic-embed-text</p>
          </div>
        </div>

        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-6 h-6 stroke-current text-accent">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z"></path>
              </svg>
              Vision/OCR
            </h3>
            <p class="text-sm">For Libraries - image processing, document OCR</p>
            <p class="text-xs text-base-content/70 mt-2">Examples: qwen3-vl, gemma3, gpt-4o</p>
          </div>
        </div>

        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title">
              <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="inline-block w-6 h-6 stroke-current text-info">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"></path>
              </svg>
              Function Calling
            </h3>
            <p class="text-sm">For Lists - structured data extraction from documents</p>
            <p class="text-xs text-base-content/70 mt-2">Examples: gpt-4o, qwen3, gemma3</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Where Models Are Used -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Where to Select Models</h2>
      <div class="space-y-4">
        <div class="collapse collapse-arrow bg-base-100 shadow-lg">
          <input type="radio" name="model-usage" checked />
          <div class="collapse-title text-xl font-medium">
            Library Settings - Embedding Model
          </div>
          <div class="collapse-content">
            <p class="mb-2">Used for generating vector embeddings to enable semantic search</p>
            <div class="text-sm text-base-content/70 space-y-1">
              <p><strong>Where:</strong> Library Settings ‚Üí Embedding Model dropdown</p>
              <p><strong>Required Capability:</strong> Embeddings</p>
              <p><strong>Recommended:</strong> text-embedding-3-small (OpenAI), nomic-embed-text (Ollama)</p>
              <p class="text-xs mt-2 italic">üí° Tip: Changing the embedding model requires reprocessing all documents</p>
            </div>
          </div>
        </div>

        <div class="collapse collapse-arrow bg-base-100 shadow-lg">
          <input type="radio" name="model-usage" />
          <div class="collapse-title text-xl font-medium">
            Library Settings - OCR Model
          </div>
          <div class="collapse-content">
            <p class="mb-2">Used for extracting text from images and scanned PDFs via Optical Character Recognition</p>
            <div class="text-sm text-base-content/70 space-y-1">
              <p><strong>Where:</strong> Library Settings ‚Üí Advanced ‚Üí OCR Model dropdown</p>
              <p><strong>Required Capability:</strong> Vision</p>
              <p><strong>Recommended (Ollama):</strong> qwen2.5-vl (3B/7B/72B), qwen3-vl (2B/32B), gemma3 (1B/4B/12B/27B)</p>
              <p><strong>Recommended (OpenAI):</strong> gpt-4o-mini (cost-effective), gpt-4o, o3 (reasoning)</p>
              <p class="text-xs mt-2 italic">üí° Tip: For Ollama models, choose size (e.g., 7B, 32B) based on your GPU memory</p>
            </div>
          </div>
        </div>

        <div class="collapse collapse-arrow bg-base-100 shadow-lg">
          <input type="radio" name="model-usage" />
          <div class="collapse-title text-xl font-medium">
            Assistant Settings - Chat Model
          </div>
          <div class="collapse-content">
            <p class="mb-2">Used for conversational AI when chatting with your Assistant</p>
            <div class="text-sm text-base-content/70 space-y-1">
              <p><strong>Where:</strong> Assistant Settings ‚Üí Language Model dropdown</p>
              <p><strong>Required Capability:</strong> Chat Completion</p>
              <p><strong>Recommended (Ollama):</strong> qwen3 (4B/8B/14B/32B), qwen2.5 (3B/14B/32B), gemma3 (1B/4B/12B/27B)</p>
              <p><strong>Recommended (OpenAI):</strong> gpt-4o-mini (fast/cheap), gpt-4o, o3 (reasoning)</p>
              <p class="text-xs mt-2 italic">üí° Tip: Larger models (32B, 27B) provide better answers but need more GPU memory</p>
            </div>
          </div>
        </div>

        <div class="collapse collapse-arrow bg-base-100 shadow-lg">
          <input type="radio" name="model-usage" />
          <div class="collapse-title text-xl font-medium">
            List Field Settings - Enrichment Model
          </div>
          <div class="collapse-content">
            <p class="mb-2">Used for extracting structured data from documents (e.g., extract invoice numbers, dates, amounts)</p>
            <div class="text-sm text-base-content/70 space-y-1">
              <p><strong>Where:</strong> List ‚Üí Field Settings ‚Üí Language Model dropdown</p>
              <p><strong>Required Capability:</strong> Function Calling (preferred) or Chat Completion</p>
              <p><strong>Recommended (Ollama):</strong> qwen3 (4B/8B/14B/32B), qwen2.5 (3B/14B/32B), gemma3 (1B/4B/12B/27B)</p>
              <p><strong>Recommended (OpenAI):</strong> gpt-4o-mini (fast/cheap), gpt-4o, o3 (reasoning)</p>
              <p class="text-xs mt-2 italic">üí° Tip: Larger models provide better structured extraction but need more GPU memory</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Usage Tracking -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Monitoring Usage & Costs</h2>
      <div class="prose max-w-none">
        <p>George AI automatically tracks usage for all AI models to help you understand costs and optimize performance.</p>
      </div>
      <div class="grid md:grid-cols-3 gap-4 mt-4">
        <div class="stat bg-base-200 rounded-lg">
          <div class="stat-title">Total Requests</div>
          <div class="stat-value text-3xl">5,247</div>
          <div class="stat-desc">Across all models this month</div>
        </div>
        <div class="stat bg-base-200 rounded-lg">
          <div class="stat-title">Total Tokens</div>
          <div class="stat-value text-3xl">2.4M</div>
          <div class="stat-desc">Input + output tokens</div>
        </div>
        <div class="stat bg-base-200 rounded-lg">
          <div class="stat-title">Estimated Cost</div>
          <div class="stat-value text-3xl">$12</div>
          <div class="stat-desc">OpenAI models only</div>
        </div>
      </div>

      <div class="alert alert-info mt-6">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
        <div>
          <h3 class="font-bold">Usage Tracking Details</h3>
          <p class="text-sm">View detailed usage per model in the AI Models page. Usage includes request count, token usage, and average processing time.</p>
        </div>
      </div>
    </section>

    <!-- Configuring AI Providers -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Configuring AI Providers</h2>
      <div class="alert alert-info mb-4">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
        <div>
          <h3 class="font-bold">Required Setup</h3>
          <p class="text-sm">Every workspace needs at least one AI provider (Ollama or OpenAI) configured to use AI features like embeddings, chat, and enrichments.</p>
        </div>
      </div>

      <div class="prose max-w-none mb-6">
        <p><strong>How to configure providers for your workspace:</strong></p>
        <ol class="list-decimal list-inside space-y-2">
          <li>Go to <strong>Settings ‚Üí AI Services</strong> in your workspace</li>
          <li>Click <strong>"Add Provider"</strong></li>
          <li>Configure the provider details (see below)</li>
          <li>Click <strong>"Save"</strong> and then <strong>"Sync Models"</strong> to discover available models</li>
        </ol>
      </div>

      <div class="grid md:grid-cols-2 gap-6 mb-6">
        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title text-lg">Ollama Configuration</h3>
            <div class="text-sm space-y-2">
              <p><strong>Provider:</strong> Select "Ollama"</p>
              <p><strong>Name:</strong> Descriptive name (e.g., "GPU Server 1")</p>
              <p><strong>Base URL:</strong> API endpoint (e.g., http://ollama:11434)</p>
              <p><strong>API Key:</strong> Optional (leave empty if not required)</p>
              <p><strong>VRAM:</strong> GPU memory in GB (e.g., 32) - used for load balancing</p>
            </div>
          </div>
        </div>

        <div class="card bg-base-100 shadow-lg">
          <div class="card-body">
            <h3 class="card-title text-lg">OpenAI Configuration</h3>
            <div class="text-sm space-y-2">
              <p><strong>Provider:</strong> Select "OpenAI"</p>
              <p><strong>Name:</strong> Descriptive name (e.g., "OpenAI Production")</p>
              <p><strong>Base URL:</strong> Optional (defaults to https://api.openai.com/v1)</p>
              <p><strong>API Key:</strong> Required (your OpenAI API key)</p>
            </div>
          </div>
        </div>
      </div>

      <div class="alert alert-success mb-4">
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
        <div>
          <h3 class="font-bold">Pro Tip: Multiple Instances</h3>
          <p class="text-sm">You can add multiple provider instances to the same workspace for load balancing and high availability. See details below.</p>
        </div>
      </div>

      <div class="collapse collapse-arrow bg-base-100 shadow-lg mt-4">
        <input type="checkbox" />
        <div class="collapse-title text-lg font-medium">
          Advanced: Multiple Instances for Load Balancing
        </div>
        <div class="collapse-content">
          <div class="text-sm space-y-6">
            <div>
              <p class="mb-2">
                For high-load scenarios, you can add multiple instances of the same provider type to distribute AI processing across multiple servers.
              </p>
              <p class="font-semibold mb-2 mt-4">Benefits of Multiple Instances:</p>
              <ul class="list-disc list-inside space-y-1 ml-2">
                <li><strong>Load Distribution:</strong> Spread AI requests across multiple GPU servers</li>
                <li><strong>High Availability:</strong> Automatic failover if one server goes offline</li>
                <li><strong>Scalability:</strong> Add more capacity as your workload grows</li>
              </ul>
            </div>

            <div>
              <p class="font-semibold mb-2">How to Add Multiple Instances:</p>
              <ol class="list-decimal list-inside space-y-1 ml-2">
                <li>Click "Add Provider" for each additional Ollama server you have</li>
                <li>Give each instance a unique name (e.g., "GPU Server 1", "GPU Server 2")</li>
                <li>Configure the base URL pointing to each server</li>
                <li>Set the VRAM value for each instance (used for intelligent routing)</li>
                <li>After adding all instances, click "Sync Models" to discover available models</li>
              </ol>
            </div>

            <div>
              <p class="font-semibold mb-2">‚öôÔ∏è Automatic Load Balancing (Ollama Only)</p>
              <p class="mb-2">When multiple Ollama instances are configured, George AI automatically:</p>
              <ul class="list-disc list-inside space-y-1 ml-2">
                <li>Routes requests to the instance with the most available GPU memory</li>
                <li>Checks which instances have the requested model loaded</li>
                <li>Performs automatic failover if an instance goes offline</li>
                <li>Deduplicates models (same model on multiple instances = one entry in dropdowns)</li>
                <li>Monitors instance health and load in real-time</li>
              </ul>
              <p class="text-xs mt-3 italic">üí° Note: Load balancing is Ollama-specific. For OpenAI, you typically only need one provider instance per workspace.</p>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Troubleshooting -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Troubleshooting</h2>
      <div class="overflow-x-auto">
        <table class="table table-zebra">
          <thead>
            <tr>
              <th>Issue</th>
              <th>Possible Cause</th>
              <th>Solution</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>No models appear after sync</td>
              <td>No providers configured</td>
              <td>Configure at least one provider (Ollama or OpenAI) and restart the application. Then sync models.</td>
            </tr>
            <tr>
              <td>Sync fails for OpenAI</td>
              <td>Invalid API key or network issue</td>
              <td>Check Settings ‚Üí AI Services and verify the OpenAI provider's API Key is correct. Check logs for error details.</td>
            </tr>
            <tr>
              <td>Sync fails for Ollama</td>
              <td>Ollama not running or incorrect URL</td>
              <td>Check Settings ‚Üí AI Services and verify the Ollama provider's Base URL is correct and accessible. Ensure Ollama service is running.</td>
            </tr>
            <tr>
              <td>Model not available in dropdown</td>
              <td>Model is disabled or doesn't have required capability</td>
              <td>Go to Admin ‚Üí AI Models and enable the model. Verify it has the required capability (e.g., embeddings, chat).</td>
            </tr>
            <tr>
              <td>OCR not working on images</td>
              <td>No vision-capable model selected</td>
              <td>Select a vision model in Library Settings ‚Üí OCR Model (e.g., gpt-4o, llama3.2-vision)</td>
            </tr>
            <tr>
              <td>High OpenAI costs</td>
              <td>Using expensive models for all operations</td>
              <td>Use smaller models for embeddings (text-embedding-3-small) and consider Ollama for high-volume operations.</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- Best Practices -->
    <section class="mb-12">
      <h2 class="text-3xl font-bold mb-6">Best Practices</h2>
      <div class="space-y-4">
        <div class="alert alert-success">
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
          <div>
            <h3 class="font-bold">Mix Providers for Cost Optimization</h3>
            <p class="text-sm">Use Ollama for high-volume operations (embeddings) and OpenAI for quality-critical tasks (chat, OCR)</p>
          </div>
        </div>
        <div class="alert alert-info">
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 16h-1v-4h-1m1-4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"></path></svg>
          <div>
            <h3 class="font-bold">Sync Models Regularly</h3>
            <p class="text-sm">When you add new models to Ollama or OpenAI releases new models, re-sync to make them available</p>
          </div>
        </div>
        <div class="alert alert-warning">
          <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" class="stroke-current shrink-0 w-6 h-6"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"></path></svg>
          <div>
            <h3 class="font-bold">Don't Disable Models in Active Use</h3>
            <p class="text-sm">Check usage statistics before disabling. If a model is used by Libraries/Assistants/Lists, they'll need reconfiguration.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Next Steps -->
    <section>
      <div class="card bg-primary text-primary-content">
        <div class="card-body">
          <h2 class="card-title text-2xl">Related Topics</h2>
          <div class="card-actions flex-wrap mt-4">
            <a href="/docs/workspaces" class="btn btn-secondary">
              Workspaces ‚Üí
            </a>
            <a href="/docs/admin/ai-services" class="btn btn-ghost btn-outline border-white text-white hover:bg-white hover:text-primary">
              AI Services & Providers
            </a>
            <a href="/docs/libraries" class="btn btn-ghost btn-outline border-white text-white hover:bg-white hover:text-primary">
              Configure Libraries
            </a>
            <a href="/docs/assistants" class="btn btn-ghost btn-outline border-white text-white hover:bg-white hover:text-primary">
              Create Assistants
            </a>
            <a href="/docs/enrichments" class="btn btn-ghost btn-outline border-white text-white hover:bg-white hover:text-primary">
              Setup Enrichments
            </a>
            <a href="/docs/embeddings" class="btn btn-ghost btn-outline border-white text-white hover:bg-white hover:text-primary">
              Understanding Embeddings
            </a>
          </div>
        </div>
      </div>
    </section>

  </div>
</Layout>
