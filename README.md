# George AI Project

## Getting Started

### 1. Re-open the repository in a **DevContainer**.

- DevContainers likely to have issues on Windows machines.

---

### 2. `.env` files:

- you need `.env` files in the directory you start the app from. If you start from **root**, setup `.env` file in the **root**, `pnpm dev` will start **george-ai** server on port `3003` and **chat-web** on `3001`. You can also start two of them separately, in this case you'd need to setup `.env` files in `apps/georgeai-server` and `apps/chat-web`.

- if you run prisma scripts in `packages/pothos-graphql` (ex. `pnpm prisma generate`), you need to setup `.env` file in it as well.

Use `env.example` files as the references.

---

### 3. Ports Overview

- **Port 3003**: GraphQL backend
- **Port 5432**: George-Ai DB
- **Port 3001**: Frontend
- **Port 11235**: crawl4ai
- **Port 8180**: keycloak
- **Port 5433**: keycloak DB
- **Port 8108**: typesense

**Vite** provides Hot Module Replacement (HMR) by establishing a WebSocket connection between the browser and the dev server. The **Vite** dev server automatically starts an HTTP server and creates a **WebSocket (WS)** server on the same host but with a dynamically assigned port. We enhance this setup with a custom **Vite** plugin that extracts the HMR WebSocket port and writes it to **app.config.ts** and an automatic port opening based on VSCode settings.

---

### 4. Set Up Keycloak

1. Open `http://localhost:8180` in your browser and log in using the credentials:

   - **Username:** `admin`
   - **Password:** `admin`

2. Create a new Realm using the value of `KEYCLOAK_REALM` from your `.env` file.

3. In the left sidebar, click **Clients** and then click **Create Client**.
   Use the value of `KEYCLOAK_CLIENT_ID` from your `.env` file as the **Client ID**.

   Add the following URLs to the fields below:

   - **Valid Redirect URIs:**
     `http://localhost:3001`,
     `http://localhost:3001/*`
   - **Valid Post Logout Redirect URIs:**
     `http://localhost:3001`,
     `http://localhost:3001/*`
   - **Web Origins:**
     `http://localhost:3001`,
     `http://localhost:3001/*`

4. Navigate to the **Users** section and click **Add User**.
   Fill in the required fields, then click **Create** at the bottom of the form.

5. After the user is created:

   - Go to the **Credentials** tab, set a password, and ensure **Temporary** is set to **Off**.
   - Go to the **Details** tab and provide:
     - **First Name**
     - **Last Name**
     - **Email**
     - Enable **Email Verified** by toggling the switch.

6. In the left sidebar, go to **Identity Providers**.
   Choose a provider (e.g., Google, GitHub, or OpenID Connect) and configure it using the required credentials (e.g., **Client ID** and **Client Secret**).

Docs for setting up an OAuth app in:

- Google: https://support.google.com/cloud/answer/6158849?hl=en
- GitHub: https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/creating-an-oauth-app
- LinkedIn: https://techdocs.akamai.com/identity-cloud/docs/the-linkedin-oauth-20-social-login-configuration-guide

---

### 5. Migrate Database

Navigate to `packages/pothos-graphql` and run:

```bash
pnpm prisma migrate dev
```

---

### 6. Start Development

You can run the app from root using following command

```bash
pnpm dev
```

However, `georgeai-server` is not stable and breaks on file changes in Vite dev mode, so you would need to restart the backend server often. This will change in the future. As a temporary solution, open two separate terminal windows for `apps/georgeai-server` and `apps/chat-web` and run the command above in each.

Enjoy.

# Flow

```mermaid

flowchart TD

%% 1. Knowledge Sources
subgraph Knowledge_Sources["ğŸ“– Knowledge Sources"]
  Document_Uploads["â¬†ï¸ Document Uploads"]
  Crawlers["ğŸ” Crawlers"]
  Confluence["ğŸ”— Confluence Connector"]
  Jira["ğŸ”— Jira Connector"]
  SAP["ğŸ”— SAP Connector"]
  Email["âœ‰ï¸ Email Connector"]
  Other["ğŸ”Œ Other Connectors"]
end

%% 2. Knowledge Libraries & Indexing & Embedding
subgraph Knowledge_Libraries["ğŸ—ƒï¸ Knowledge Libraries & Indexing & Embedding"]
  Indexing["ğŸ” Indexing"]
  Embedding["ğŸ“ Embedding"]
end

%% 3. Dataset Generation
subgraph Dataset_Generation["ğŸ“„ Dataset Generation"]
  AutoGenerated["âš¡ Auto-Generated Datasets"]
  CurativeUI["âœï¸ Curative UI"]
end

%% 4. Fine-Tuned Models
subgraph Fine_Tuning["ğŸ–¥ï¸ Fine-Tuning"]
  CustomModels["ğŸ§  Custom Deep Learning Models"]
  IncrementalFT["ğŸ”„ Incremental Fine-Tuning\n(Nightly & Weekly)"]
end

%% 5. AI Assistants
subgraph AI_Assistants["ğŸ¤– AI Assistants"]
  Department["ğŸ‘¤ Department Assistants"]
  Project["ğŸ‘¤ Project Assistants"]
  Team["ğŸ‘¤ Team Assistants"]
  RAG["ğŸ” RAG Access"]
end

%% 6. User Interfaces
subgraph User_Interfaces["ğŸ–¥ï¸ User Interfaces"]
  Chat["ğŸ’¬ Chat"]
  VibeApps["ğŸ“± Vibe-Coded Apps"]
  SearchPrompt["ğŸ” Search Prompt"]
end

%% 7. Usage Data
Usage_Data["ğŸ“ˆ Usage Data"]

%% Relationships
Knowledge_Sources --> Knowledge_Libraries
Knowledge_Libraries --> Dataset_Generation
Dataset_Generation --> Fine_Tuning
Fine_Tuning --> CustomModels
IncrementalFT --> CustomModels
AI_Assistants --> Knowledge_Libraries
User_Interfaces --> AI_Assistants
User_Interfaces --> Usage_Data
Usage_Data --> Dataset_Generation
CurativeUI --> AutoGenerated
CustomModels --> AI_Assistants
SearchPrompt --> Knowledge_Libraries
AI_Assistants --> CustomModels

```

# Architecture

```mermaid
flowchart TD

  subgraph Apps
    chatWeb[chat-web]
    georgeaiServer[georgeai-server]
  end

  subgraph Packages
    pothosGraphQL[pothos-graphql]
    langchainChat[langchain-chat]
    crawl4aiClient[crawl4ai-client]
    webUtils[web-utils]
  end

  subgraph Services
    typesense[Typesense<br>Port: 8108]
    chatwebDB[Chatweb DB<br>Port: 5434]
    keycloakDB[Keycloak DB<br>Port: 5433]
    keycloak[Keycloak<br>Port: 8180]
    crawl4ai[Crawl4AI<br>Port: 11235]
    ollama[OLLAMA<br>Port: 11434]
    fileStorage[File Storage]
  end

  %% Apps and their dependencies
  chatWeb --> keycloak
  chatWeb --> webUtils
  chatWeb --> georgeaiServer
  georgeaiServer --> pothosGraphQL
  georgeaiServer --> fileStorage

  %% Package dependencies
  crawl4aiClient --> crawl4ai
  pothosGraphQL --> chatwebDB
  pothosGraphQL --> typesense
  pothosGraphQL --> langchainChat
  pothosGraphQL --> crawl4aiClient
  langchainChat --> ollama
  langchainChat --> typesense
  pothosGraphQL --> fileStorage

  %% Services and their relationships
  keycloak --> keycloakDB
```

## Components

- **LLM Service** ğŸ› ï¸
  - on backend service
  - consists of three components: GraphQL Endpoint, PDF Processor, Chains
- **GraphQL Endpoint** ğŸŒ
  - communication endpoint of the LLM Service
- **PDF Processor** ğŸ“„
  - processes the uploaded PDFs
  - extracts the text and embeddings
  - writes the extracted data and the embedding to the LLM Database
- **Chains** ğŸ”—
  - uses the embeddings in LLM Database as a retriever
  - contains the chains for chatbot and travel planner
- **LLM Database** ğŸ—ƒï¸
  - stores the extracted data and embeddings
  - must be database with vector search support
- **Frontend** ğŸ’»
  - one Frontend App with two routes: Chatbot and Travel Planner
- **Chatbot** ğŸ¤–
  - bot to chat about the PDFs
